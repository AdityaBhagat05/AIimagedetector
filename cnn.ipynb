{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b33555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee38d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6032c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3535e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23bb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2,\n",
    "                           contrast=0.2,\n",
    "                           saturation=0.2,\n",
    "                           hue=0.05),\n",
    "    transforms.RandomAffine(degrees=0,translate=(0.05,0.05),shear=5),\n",
    "    transforms.GaussianBlur(kernel_size=3,sigma=(0.1,2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='datasetresized/train', transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root='datasetresized/test', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1961cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe6ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['fake', 'real']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b799c",
   "metadata": {},
   "source": [
    "Without frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17bd5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Bhagat\\Desktop\\ml\\AIimagedetector\\AIimageDetector\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya Bhagat\\Desktop\\ml\\AIimagedetector\\AIimageDetector\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 2)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684e64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea1f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f8b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b3f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "dataset_sizes = {'train': len(train_loader.dataset), 'val': len(test_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e76a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic function\n",
    "# def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "#     since = time.time()\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         # Each epoch has a training and validation phase\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()  # Set model to training mode\n",
    "#             else:\n",
    "#                 model.eval()   # Set model to evaluation mode\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "\n",
    "#             # Iterate over data.\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # forward\n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "\n",
    "#                     # backward + optimize only if in training phase\n",
    "#                     if phase == 'train':\n",
    "#                         optimizer.zero_grad()\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "\n",
    "#                 # Statistics\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "#             print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#             # Deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#         print()\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "#     print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "#     # Load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e155cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler,\n",
    "                dataloaders, dataset_sizes, device,\n",
    "                num_epochs, stage='warmup'):\n",
    "\n",
    "    import time, copy\n",
    "    since = time.time()\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Stage setup: freeze or unfreeze\n",
    "    if stage == 'warmup':\n",
    "        for name, p in model.named_parameters():\n",
    "            p.requires_grad = ('fc' in name)\n",
    "    else:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}  Stage: {stage}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "        epoch_acc  = {'train': 0.0, 'val': 0.0}\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase=='train' else model.eval()\n",
    "            loader = dataloaders[phase]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "            epoch_loss[phase] = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc[phase]  = running_corrects / dataset_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss[phase]:.4f} Acc: {epoch_acc[phase]:.4f}')\n",
    "\n",
    "        # Step scheduler ONCE per epoch\n",
    "        if stage == 'warmup':\n",
    "            scheduler.step(epoch_loss['train'])\n",
    "        else:\n",
    "            scheduler.step(epoch_loss['val'])\n",
    "\n",
    "        # Save best weights if current val acc is better\n",
    "        if epoch_acc['val'] > best_acc:  # Removed stage condition\n",
    "            best_acc = epoch_acc['val']\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074001a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4911 Acc: 0.7608\n",
      "val Loss: 0.4424 Acc: 0.7944\n",
      "\n",
      "Epoch 1/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4682 Acc: 0.7764\n",
      "val Loss: 0.4383 Acc: 0.7969\n",
      "\n",
      "Epoch 2/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4633 Acc: 0.7819\n",
      "val Loss: 0.4327 Acc: 0.8001\n",
      "\n",
      "Epoch 3/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4571 Acc: 0.7860\n",
      "val Loss: 0.4433 Acc: 0.7950\n",
      "\n",
      "Epoch 4/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4603 Acc: 0.7831\n",
      "val Loss: 0.4483 Acc: 0.7933\n",
      "\n",
      "Training complete in 50m 50s\n",
      "Best val Acc: 0.8001\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, scheduler,\n",
    "                    dataloaders, dataset_sizes, device,\n",
    "                    num_epochs=5, stage='warmup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f846f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18_model_warmup2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae02f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.3462 Acc: 0.8510\n",
      "val Loss: 0.2318 Acc: 0.8999\n",
      "\n",
      "Epoch 1/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.2624 Acc: 0.8922\n",
      "val Loss: 0.1950 Acc: 0.9191\n",
      "\n",
      "Epoch 2/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.2269 Acc: 0.9077\n",
      "val Loss: 0.1777 Acc: 0.9284\n",
      "\n",
      "Epoch 3/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.2069 Acc: 0.9160\n",
      "val Loss: 0.1768 Acc: 0.9294\n",
      "\n",
      "Epoch 4/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1902 Acc: 0.9246\n",
      "val Loss: 0.1867 Acc: 0.9303\n",
      "\n",
      "Epoch 5/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1768 Acc: 0.9291\n",
      "val Loss: 0.1709 Acc: 0.9331\n",
      "\n",
      "Epoch 6/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1645 Acc: 0.9349\n",
      "val Loss: 0.1751 Acc: 0.9361\n",
      "\n",
      "Epoch 7/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9385\n",
      "val Loss: 0.1733 Acc: 0.9358\n",
      "\n",
      "Epoch 8/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1438 Acc: 0.9432\n",
      "val Loss: 0.2081 Acc: 0.9216\n",
      "\n",
      "Epoch 9/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9483\n",
      "val Loss: 0.1819 Acc: 0.9372\n",
      "\n",
      "Epoch 10/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1254 Acc: 0.9501\n",
      "val Loss: 0.2043 Acc: 0.9253\n",
      "\n",
      "Epoch 11/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.0967 Acc: 0.9625\n",
      "val Loss: 0.1893 Acc: 0.9391\n",
      "\n",
      "Epoch 12/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9658\n",
      "val Loss: 0.1822 Acc: 0.9406\n",
      "\n",
      "Epoch 13/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.0821 Acc: 0.9686\n",
      "val Loss: 0.2075 Acc: 0.9370\n",
      "\n",
      "Epoch 14/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.0758 Acc: 0.9705\n",
      "val Loss: 0.1946 Acc: 0.9391\n",
      "\n",
      "Training complete in 50m 54s\n",
      "Best val Acc: 0.9406\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.fc.parameters(),    'lr': 1e-3},\n",
    "    {'params': [p for n,p in model.named_parameters() if 'layer4' not in n and 'fc' not in n],\n",
    "     'lr': 1e-5}\n",
    "])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "model = train_model(model, criterion, optimizer, scheduler,\n",
    "                    dataloaders, dataset_sizes, device,\n",
    "                    num_epochs=15, stage='finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b30e12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18_model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a8d6a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acf5f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),          # Resize to match training input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Same as training\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9606fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    # Open and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    input_batch = input_batch.to(device)     # Move to device\n",
    "\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c25e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(input_batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    probabilities = F.softmax(output, dim=1)[0]\n",
    "    predicted_class_idx = torch.argmax(probabilities).item()\n",
    "    confidence = probabilities[predicted_class_idx].item()\n",
    "    predicted_class = classes[predicted_class_idx]\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ef1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: fake with 79.60% confidence\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = r'C:\\Users\\Aditya Bhagat\\Desktop\\ml\\AIimagedetector\\sunflowers-8175248_1920.jpg'  # Replace with your image path\n",
    "\n",
    "# Load and preprocess\n",
    "input_batch = predict_image(image_path)\n",
    "\n",
    "# Get prediction\n",
    "class_name, confidence = get_prediction(input_batch)\n",
    "print(f'Predicted: {class_name} with {confidence*100:.2f}% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0510f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# After validation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m cm = confusion_matrix(\u001b[43mall_labels\u001b[49m, all_preds)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(cm)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16610d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIimageDetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
