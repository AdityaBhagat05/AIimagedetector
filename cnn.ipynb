{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b33555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee38d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6032c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3535e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d23bb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2,\n",
    "                           contrast=0.2,\n",
    "                           saturation=0.2,\n",
    "                           hue=0.05),\n",
    "    transforms.RandomAffine(degrees=0,translate=(0.05,0.05),shear=5),\n",
    "    transforms.GaussianBlur(kernel_size=3,sigma=(0.1,2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ede974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='datasetmerged/train', transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root='datasetmerged/test', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea1961cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe6ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['fake', 'real']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b799c",
   "metadata": {},
   "source": [
    "Without frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17bd5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya Bhagat\\Desktop\\ml\\AIimagedetector\\AIimageDetector\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya Bhagat\\Desktop\\ml\\AIimagedetector\\AIimageDetector\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 2)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "684e64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ea1f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0f8b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "379436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84b3f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "dataset_sizes = {'train': len(train_loader.dataset), 'val': len(test_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e76a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic function\n",
    "# def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "#     since = time.time()\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         # Each epoch has a training and validation phase\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()  # Set model to training mode\n",
    "#             else:\n",
    "#                 model.eval()   # Set model to evaluation mode\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "\n",
    "#             # Iterate over data.\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # forward\n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "\n",
    "#                     # backward + optimize only if in training phase\n",
    "#                     if phase == 'train':\n",
    "#                         optimizer.zero_grad()\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "\n",
    "#                 # Statistics\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "#             print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#             # Deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#         print()\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "#     print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "#     # Load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e155cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, criterion, optimizer, scheduler,\n",
    "#                 dataloaders, dataset_sizes, device,\n",
    "#                 num_epochs, stage='warmup'):\n",
    "\n",
    "#     import time, copy\n",
    "#     since = time.time()\n",
    "#     best_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "\n",
    "#     # Stage setup: freeze or unfreeze\n",
    "#     if stage == 'warmup':\n",
    "#         for name, p in model.named_parameters():\n",
    "#             p.requires_grad = ('fc' in name)\n",
    "#     else:\n",
    "#         for p in model.parameters():\n",
    "#             p.requires_grad = True\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs-1}  Stage: {stage}')\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "#         epoch_acc  = {'train': 0.0, 'val': 0.0}\n",
    "\n",
    "#         for phase in ['train', 'val']:\n",
    "#             model.train() if phase=='train' else model.eval()\n",
    "#             loader = dataloaders[phase]\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "\n",
    "#             for inputs, labels in loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#                 with torch.set_grad_enabled(phase=='train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "\n",
    "#                     if phase == 'train':\n",
    "#                         optimizer.zero_grad()\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "#             epoch_loss[phase] = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc[phase]  = running_corrects / dataset_sizes[phase]\n",
    "#             print(f'{phase} Loss: {epoch_loss[phase]:.4f} Acc: {epoch_acc[phase]:.4f}')\n",
    "\n",
    "#         # Step scheduler ONCE per epoch\n",
    "#         if stage == 'warmup':\n",
    "#             scheduler.step(epoch_loss['train'])\n",
    "#         else:\n",
    "#             scheduler.step(epoch_loss['val'])\n",
    "\n",
    "#         # Save best weights if current val acc is better\n",
    "#         if epoch_acc['val'] > best_acc:  # Removed stage condition\n",
    "#             best_acc = epoch_acc['val']\n",
    "#             best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#         print()\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "#     print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "#     model.load_state_dict(best_wts)\n",
    "#     return model\n",
    "def train_model(model, criterion, optimizer, scheduler,\n",
    "                dataloaders, dataset_sizes, device,\n",
    "                num_epochs, stage='warmup',\n",
    "                patience=2, min_delta=1e-4):\n",
    "    import time, copy\n",
    "    since = time.time()\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Early‐stopping trackers\n",
    "    epochs_no_improve = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Stage setup: freeze or unfreeze\n",
    "    if stage == 'warmup':\n",
    "        for name, p in model.named_parameters():\n",
    "            p.requires_grad = ('fc' in name)\n",
    "    else:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}  Stage: {stage}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "        epoch_acc  = {'train': 0.0, 'val': 0.0}\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase=='train' else model.eval()\n",
    "            loader = dataloaders[phase]\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "            epoch_loss[phase] = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc[phase]  = running_corrects / dataset_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss[phase]:.4f} Acc: {epoch_acc[phase]:.4f}')\n",
    "\n",
    "        # Scheduler step\n",
    "        monitor_loss = epoch_loss['train'] if stage=='warmup' else epoch_loss['val']\n",
    "        scheduler.step(monitor_loss)\n",
    "\n",
    "        # Early‐stopping check (on validation loss)\n",
    "        val_loss = epoch_loss['val']\n",
    "        if best_val_loss - val_loss > min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f'No improvement in val loss for {epochs_no_improve} epoch(s).')\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs.')\n",
    "            break\n",
    "\n",
    "        # Save best weights based on val acc\n",
    "        if epoch_acc['val'] > best_acc:\n",
    "            best_acc = epoch_acc['val']\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074001a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4480 Acc: 0.7906\n",
      "val Loss: 0.5366 Acc: 0.7525\n",
      "\n",
      "Epoch 1/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4316 Acc: 0.8027\n",
      "val Loss: 0.5228 Acc: 0.7582\n",
      "\n",
      "Epoch 2/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4278 Acc: 0.8030\n",
      "val Loss: 0.5391 Acc: 0.7507\n",
      "No improvement in val loss for 1 epoch(s).\n",
      "\n",
      "Epoch 3/4  Stage: warmup\n",
      "----------\n",
      "train Loss: 0.4234 Acc: 0.8063\n",
      "val Loss: 0.5699 Acc: 0.7438\n",
      "No improvement in val loss for 2 epoch(s).\n",
      "Early stopping triggered after 4 epochs.\n",
      "Training complete in 14m 31s\n",
      "Best val Acc: 0.7582\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, scheduler,\n",
    "                    dataloaders, dataset_sizes, device,\n",
    "                    num_epochs=5, stage='warmup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f846f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18_model_warmup4.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae02f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.2945 Acc: 0.8749\n",
      "val Loss: 0.3496 Acc: 0.8617\n",
      "\n",
      "Epoch 1/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.2230 Acc: 0.9080\n",
      "val Loss: 0.3188 Acc: 0.8814\n",
      "\n",
      "Epoch 2/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9191\n",
      "val Loss: 0.2449 Acc: 0.9055\n",
      "\n",
      "Epoch 3/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1824 Acc: 0.9273\n",
      "val Loss: 0.3642 Acc: 0.8973\n",
      "No improvement in val loss for 1 epoch(s).\n",
      "\n",
      "Epoch 4/14  Stage: finetune\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.9337\n",
      "val Loss: 0.2886 Acc: 0.9028\n",
      "No improvement in val loss for 2 epoch(s).\n",
      "Early stopping triggered after 5 epochs.\n",
      "Training complete in 20m 15s\n",
      "Best val Acc: 0.9055\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.fc.parameters(),    'lr': 1e-3},\n",
    "    {'params': [p for n,p in model.named_parameters() if 'layer4' not in n and 'fc' not in n],\n",
    "     'lr': 1e-5}\n",
    "])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "model = train_model(model, criterion, optimizer, scheduler,\n",
    "                    dataloaders, dataset_sizes, device,\n",
    "                    num_epochs=15, stage='finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b30e12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18_model4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a8d6a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf5f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),          # Resize to match training input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Same as training\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9606fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    # Open and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    input_batch = input_batch.to(device)     # Move to device\n",
    "\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c25e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(input_batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    probabilities = F.softmax(output, dim=1)[0]\n",
    "    predicted_class_idx = torch.argmax(probabilities).item()\n",
    "    confidence = probabilities[predicted_class_idx].item()\n",
    "    predicted_class = classes[predicted_class_idx]\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ef1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: fake with 100.00% confidence\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = r\"\" \n",
    "\n",
    "# Load and preprocess\n",
    "input_batch = predict_image(image_path)\n",
    "\n",
    "# Get prediction\n",
    "class_name, confidence = get_prediction(input_batch)\n",
    "print(f'Predicted: {class_name} with {confidence*100:.2f}% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0510f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(r\"\", map_location='cuda')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c16610d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030726b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIimageDetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
